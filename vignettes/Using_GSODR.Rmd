---
title: "Using the GSODR Package"
author: "Adam H. Sparks"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Using the GSODR Package}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction
An R package that provides a function that automates downloading and
cleaning data from the "[Global Surface Summary of the Day
(GSOD)](https://data.noaa.gov/dataset/global-surface-summary-of-the-day-gsod)"
data provided by the US National Climatic Data Center (NCDC). Stations
are individually checked for number of missing days to assure data
quality, those stations with too many missing observations as defined by the
user are omitted. All units are converted to International System of Units (SI),
e.g., inches to millimetres and Fahrenheit to Celsius. Output is saved as a
Comma Separated Value (CSV) file or in a spatial GeoPackage (GPKG) file,
implemented by most major GIS software, summarising each year by station, which
also includes vapour pressure and relative humidity variables calculated from
existing data in GSOD.

This package was largely based on Tomislav Hengl's work, [getGSOD.R](http://spatial-analyst.net/book/getGSOD.R)
in "[A Practical Guide to Geostatistical Mapping](http://spatial-analyst.net)",
with updates for speed, cross-platform functionality, and more options for data
retrieval and error correction.

For more information see the description of the data provided by NCDC,
<http://www7.ncdc.noaa.gov/CDO/GSOD_DESC.txt>.

# Using the package

## Load GSODR

```{r load_library}
library(GSODR)
```

## Plot Global Station Locations

The `get_GSOD()` function automatically fetches the most recent station data from
the NCDC website and removes stations that are missing data (as shown below).
Using this data we can plot the station locations that are included in GSOD that
provide valid geo-locations after cleaning.

```{r fetch_stations}
  GSOD_stations <- readr::read_csv(
    "ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv",
    col_types = "ccccccddddd",
    col_names = c("USAF", "WBAN", "STN_NAME", "CTRY", "STATE", "CALL",
                  "LAT", "LON", "ELEV_M", "BEGIN", "END"), skip = 1)

  GSOD_stations[GSOD_stations == -999.9] <- NA
  GSOD_stations[GSOD_stations == -999] <- NA

  GSOD_stations <- GSOD_stations[!is.na(GSOD_stations$LAT) & !is.na(GSOD_stations$LON), ]
  GSOD_stations <- GSOD_stations[GSOD_stations$LAT != 0 & GSOD_stations$LON != 0, ]
  GSOD_stations <- GSOD_stations[GSOD_stations$LAT > -90 & GSOD_stations$LAT < 90, ]
  GSOD_stations <- GSOD_stations[GSOD_stations$LON > -180 & GSOD_stations$LON < 180, ]
  GSOD_stations$STNID <- as.character(paste(GSOD_stations$USAF, GSOD_stations$WBAN, sep = "-"))
```

Using [ggplot2](https://cran.r-project.org/web/packages/ggplot2/index.html) and the [ggalt](https://cran.r-project.org/web/packages/ggalt/index.html) package it is
possible to plot the station locations using alpha transparency to see the
densest part of the network and use the Robinson projection for the map.

```{r plot_stations, fig.width=7, fig.height=7, fig.cap="GSOD Station Locations"}
library(ggplot2)
library(ggalt)

ggplot(GSOD_stations, aes(x = LON, y = LAT)) +
  geom_point(alpha = 0.1) +
  coord_proj("+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs") +
  theme_bw()

```

## Find Stations in Australia

GSODR provides lists of weather station locations and elevation values. Using
dplyr, we can find all the stations in Australia.
```{r australia_stations, message=FALSE, warning=FALSE}
library(dplyr)
# left_join the the station data with the country list
station_locations <- left_join(GSOD_stations, GSODR::GSOD_country_list, by = c("CTRY" = "FIPS"))

# create data.frame for Australia only
Oz <- filter(station_locations, COUNTRY_NAME == "AUSTRALIA")
head(Oz)

# find a station in Toowoomba, Queensland
filter(Oz, STN_NAME == "TOOWOOMBA")

```

## Using the `get_GSOD()` Function in GSODR to Download a Single Station and
Year

Download weather data from the station Toowoomba, Queensland, Australia for 2010
and save it in the user's home directory using the STNID in the `station`
parameter of `get_GSOD()`.

```{r Toowoomba_Airport, eval=TRUE}
get_GSOD(years = 2010, station = "955510-99999", dsn = "~/",
         filename = "Toowoomba_Airport")
```

## Find Stations Within a Specified Distance of a Point

Using the `nearest_stations()` function, you can find stations closest to a
given point specified by latitude and longitude in decimal degrees. This can be
used to generate a vector to pass along to `get_GSOD()` and download the
stations of interest.

There are missing stations in this query. Not all that are listed and queried
actually have files on the server.

```{r spatial_query, message}
tbar_stations <- nearest_stations(LAT = -27.5598, LON = 151.9507, distance = 50)
tbar_stations <- tbar_stations$STNID

get_GSOD(years = 2010, station = tbar_stations, dsn = "~/",
         filename = "Toowoomba_50km_2010")
```
If you wished to drop the stations, 949999-00170 and 949999-00183 from the query,
you could do this.

```{r use_nearest_stations, eval=FALSE}
remove <- c("949999-00170", "949999-00183")
tbar_stations <- tbar_stations[!tbar_stations %in% remove]

get_GSOD(years = 2010, station = tbar_stations, dsn = "~/",
         filename = "Toowoomba_50km")
```

## Plot Maximum and Miniumum Temperature Values
Using the first data downloaded for a single station, plot the temperature for
2010, setting the "-9999" value to NA on import using `read_csv` from Hadley's
`readr` package.

```{r plot_temps, fig.width=7, fig.height=7, message=FALSE, fig.cap="Toowoomba 2010 Temperatures"}
library(lubridate)
library(readr)
library(tidyr)

# Import the data for Toowoomba previously downloaded and cleaned
tbar <- read_csv("~/Toowoomba_Airport-2010.csv", na = "-9999")

# Create a dataframe of just the date and temperature values that we want to plot
tbar_temps <- tbar[, c(14, 19, 33, 35)]

# Gather the data from wide to long
tbar_temps <- gather(tbar_temps, Measurement, gather_cols = TEMP:MIN)

ggplot(data = tbar_temps, aes(x = ymd(YEARMODA), y = value,
                              colour = Measurement)) +
  geom_line() +
  scale_color_brewer(type = "qual", na.value = "black") +
  scale_y_continuous(name = "Temperature") +
  scale_x_date(name = "Date") +
  theme_bw()

```

## Creating spatial files
Because the stations provide geospatial location information, it is possible
to create a spatial file. [GeoPackage files](http://www.geopackage.org) are a
open, standards-based, platform-independent, portable, self-describing compact
format for transferring geospatial information, which handle vector files much
like shapefiles do, but eliminate many of the issues that shapefiles have with
field names and the number of files. The `get_GSOD()` function can create a
GeoPackage file, which can be used with a GIS for further analysis and mapping
with other spatial objects.

After getting weather stations for Australia and creating a GeoPackage file,
the rgdal package can import the data into R and the raster package can download
an outline of Australia useful for plotting the station locations in this
country.

```{r spatial_files, message=FALSE}

get_GSOD(years = 2015, country = "Australia", dsn = "~/", filename = "AUS",
         CSV = FALSE, GPKG = TRUE)
```

Importing the GeoPackage file can be a bit tricky. The dsn will be the full path
along with the file name. The layer to be specified is "GSOD", this is specified
in the `get_GSOD()` function and will not change. The file name, specified in the
dsn will, but the layer name will not.

```{r import_spatial_files, message=FALSE}

library(rgdal)
AUS_stations <- readOGR(dsn = path.expand("~/AUS-2015.gpkg"), layer = "GSOD")

class(AUS_stations)

print(unique(AUS_stations$STN_NAME))

```

Since GeoPackage files are formatted as SQLite databases you can use the
existing R tools for SQLite files [(J. Stachelek 2016)](https://jsta.github.io/2016/07/14/geopackage-r.html).
One easy way is using dplyr, which we've already used to filter the stations.

This option is much faster to load since it does not load the geometry.

```{r as_gpkg_database}

AUS_sqlite <- tbl(src_sqlite(path.expand("~/AUS-2015.gpkg")), "GSOD")
class(AUS_sqlite)
print(AUS_sqlite, n = 5)

```
# Generating hourly temperature data from daily using the `chillR` package

The `chillR` package from [Eike Luedeling](http://eikeluedeling.com/index.html)
has a function, `make_hourly_temps()` that can be used to temporally downscale
daily weather data to hourly using the station's latitude. Here's how that's
possible using the Toowoomba-Airport data.

To use this function it is necessary to rename the MAX, MIN, YEAR and YDAY
columns and convert the `tibble` to a standard `data.frame` object so that
`make_hourly_temps()` will recognize the columns and can operate on the
data.

```{r temporal_downscaling}
library(chillR)

# rename columns and convert the object to a standard data.frame
colnames(tbar)[colnames(tbar) == "MAX"] <- "Tmax"
colnames(tbar)[colnames(tbar) == "MIN"] <- "Tmin"
colnames(tbar)[colnames(tbar) == "YEAR"] <- "Year"
colnames(tbar)[colnames(tbar) == "YDAY"] <- "JDay"
tbar <- as.data.frame(tbar)

# generate hourly temperature values
tbar <- make_hourly_temps(tbar[, 8], tbar)

head(tbar)

```

# Notes

## Elevation Values

90 metre (90m) hole-filled SRTM digital elevation (Jarvis *et al.* 2008) was used
to identify and correct/remove elevation errors in data for station
locations between -60˚ and 60˚ latitude. This applies to cases here
where elevation was missing in the reported values as well. In case the
station reported an elevation and the DEM does not, the station reported
is taken. For stations beyond -60˚ and 60˚ latitude, the values are
station reported values in every instance. See
<https://github.com/adamhsparks/GSODR/blob/devel/data-raw/fetch_isd-history.md>
for more detail on the correction methods.

## WMO Resolution 40. NOAA Policy

*Users of these data should take into account the following (from the
[NCDC website](http://www7.ncdc.noaa.gov/CDO/cdoselect.cmd?datasetabbv=GSOD&countryabbv=&georegionabbv=)):*

> "The following data and products may have conditions placed on their 
international commercial use. They can be used within the U.S. or for
non-commercial international activities without restriction. The
non-U.S. data cannot be redistributed for commercial purposes.
Re-distribution of these data by others must provide this same
notification." [WMO Resolution 40. NOAA
Policy](http://www.wmo.int/pages/about/Resolution40.html)

# References
Stachelek, J. 2016. Using the Geopackage Format with R. 
URL: https://jsta.github.io/2016/07/14/geopackage-r.html
